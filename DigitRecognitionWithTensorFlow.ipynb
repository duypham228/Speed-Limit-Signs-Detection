{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rX8mhOLljYeM"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "BZSlp3DAjdYf"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wF5wszaj97Y"
   },
   "source": [
    "# Get Started with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DUNzJc4jTj6G"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/_index.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/_index.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hiH7AC-NTniF"
   },
   "source": [
    "This is a [Google Colaboratory](https://colab.research.google.com/notebooks/welcome.ipynb) notebook file. Python programs are run directly in the browser—a great way to learn and use TensorFlow. To run the Colab notebook:\n",
    "\n",
    "1. Connect to a Python runtime: At the top-right of the menu bar, select *CONNECT*.\n",
    "2. Run all the notebook code cells: Select *Runtime* > *Run all*.\n",
    "\n",
    "For more examples and guides (including details for this program), see [Get Started with TensorFlow](https://www.tensorflow.org/get_started/).\n",
    "\n",
    "Let's get started, import the TensorFlow library into your program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/load_data/images\n",
    "\n",
    "#images folder path\n",
    "dirname = os.getcwd()\n",
    "# curpath = os.path.join(dirname, 'dev_ws/dataset/crop-images')\n",
    "alternate = os.path.join(dirname, 'dev_ws/dataset/dataset-ml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 296 files belonging to 9 classes.\n",
      "Using 237 files for training.\n",
      "Found 296 files belonging to 9 classes.\n",
      "Using 59 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-26 14:46:41.785070: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#https://www.tensorflow.org/tutorials/keras/save_and_load\n",
    "#https://www.pythonfixing.com/2022/01/fixed-batchdataset-get-img-array-and.html \n",
    "\n",
    "#specify image dimensions\n",
    "img_height = 28\n",
    "img_width = 28\n",
    "\n",
    "#load in the dataset with train-test split\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(alternate, validation_split=0.2, subset=\"training\", seed=123,\n",
    "  image_size=(img_height, img_width))\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(alternate, validation_split=0.2, subset=\"validation\", seed=123,\n",
    "  image_size=(img_height, img_width))\n",
    "\n",
    "train_ds_unbatch = train_ds.unbatch()\n",
    "x_train = list(train_ds_unbatch.map(lambda x, y: x))\n",
    "y_train = list(train_ds_unbatch.map(lambda x, y: y))\n",
    "\n",
    "val_ds_unbatch = val_ds.unbatch()\n",
    "x_test = list(val_ds_unbatch.map(lambda x, y: x))\n",
    "y_test = list(val_ds_unbatch.map(lambda x, y: y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine our dataset. Below code was taken from https://github.com/ageron/handson-ml/blob/master/03_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Sequential([\n",
    "#   tf.keras.layers.Flatten(),\n",
    "#   tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "# ])\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(9)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 3s 136ms/step - loss: 2.1434 - accuracy: 0.1814 - val_loss: 1.9963 - val_accuracy: 0.3729\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 37ms/step - loss: 1.8077 - accuracy: 0.4430 - val_loss: 1.6622 - val_accuracy: 0.4746\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 56ms/step - loss: 1.3404 - accuracy: 0.6920 - val_loss: 1.2705 - val_accuracy: 0.6102\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.8632 - accuracy: 0.7131 - val_loss: 0.8314 - val_accuracy: 0.7627\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 57ms/step - loss: 0.5087 - accuracy: 0.8523 - val_loss: 0.8149 - val_accuracy: 0.6780\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 62ms/step - loss: 0.4602 - accuracy: 0.8143 - val_loss: 0.9044 - val_accuracy: 0.7119\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 0.3699 - accuracy: 0.8692 - val_loss: 0.4250 - val_accuracy: 0.9153\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 50ms/step - loss: 0.2692 - accuracy: 0.8987 - val_loss: 0.5460 - val_accuracy: 0.8475\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 54ms/step - loss: 0.1512 - accuracy: 0.9620 - val_loss: 0.3625 - val_accuracy: 0.8983\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 45ms/step - loss: 0.0886 - accuracy: 0.9873 - val_loss: 0.3273 - val_accuracy: 0.9322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcde1f16d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T4JfEh7kvx6m"
   },
   "source": [
    "You’ve now trained an image classifier. See [Get Started with TensorFlow](https://www.tensorflow.org/get_started/) to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hsTSsnyfF9U0"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries to handle loading and displaying images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test our model with one random image in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OscxG_BhIfa1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'PIL.Image.Image'>\n",
      "<class 'numpy.ndarray'>\n",
      "Predicted Label:  6\n",
      "Actual image: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdccd880340>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number_nine = Image.open('mnist_test/dataset-ml/0/0-m-1.jpeg')\n",
    "number_nine = image.load_img('mnist_test/6.png', target_size=(28, 28))\n",
    "print(type(number_nine))\n",
    "img_array = image.img_to_array(number_nine)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "print(type(img_preprocessed))\n",
    "print(\"Predicted Label: \", np.argmax(model.predict(img_preprocessed)))\n",
    "print('Actual image: ')\n",
    "plt.figure(figsize = (1, 1))\n",
    "plt.imshow(number_nine, cmap = 'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  7\n",
      "Actual image: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdccda4a580>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number_nine = Image.open('mnist_test/dataset-ml/0/0-m-1.jpeg')\n",
    "number_nine = image.load_img('mnist_test/dataset-ml/7/7-m-1.jpeg', target_size=(28, 28))\n",
    "img_array = image.img_to_array(number_nine)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "print(\"Predicted Label: \", np.argmax(model.predict(img_preprocessed)))\n",
    "print('Actual image: ')\n",
    "plt.figure(figsize = (1, 1))\n",
    "plt.imshow(number_nine, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label:  8\n",
      "Actual image: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdccda94730>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number_nine = Image.open('mnist_test/dataset-ml/0/0-m-1.jpeg')\n",
    "number_nine = image.load_img('mnist_test/47-8.jpeg', target_size=(28, 28))\n",
    "img_array = image.img_to_array(number_nine)\n",
    "img_batch = np.expand_dims(img_array, axis=0)\n",
    "img_preprocessed = preprocess_input(img_batch)\n",
    "print(\"Predicted Label: \", np.argmax(model.predict(img_preprocessed)))\n",
    "print('Actual image: ')\n",
    "plt.figure(figsize = (1, 1))\n",
    "plt.imshow(number_nine, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.getcwd()\n",
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.join(dirname, \"training_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cp.ckpt.data-00000-of-00001', 'checkpoint', 'cp.ckpt.index']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model as a SavedModel.\n",
    "model.save('dev_ws/saved_model/my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('dev_ws/saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the restored model\n",
    "loss, acc = new_model.evaluate(val_ds, verbose=2)\n",
    "print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))\n",
    "\n",
    "print(new_model.predict(val_ds).shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of _index.ipynb",
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/_index.ipynb",
     "timestamp": 1561490564528
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
